---
layout: post
title:  "ç†è§£ broadcasting ğŸ“¢"
date:   2024-05-26 22:39:02 +0800
categories: pytorch
---

broadcasting æœ¬è´¨æ˜¯è®©å¤§å°ä¸ç›¸åŒçš„ä¸¤ä¸ª tensor æ‹‰æŠ»åå…·æœ‰ç›¸åŒçš„å¤§å°, èƒ½å¤Ÿè¿›è¡Œæ•°å­¦è¿ç®—
![broadcasting](/assets/images/pic-broadcasting_2.png)

# é—®é¢˜
tensor è¿›è¡Œé€ä¸ªå…ƒç´ è®¡ç®—æ—¶, é€šå¸¸è¦æ±‚äºŒè€… shape è¦åŒ¹é…
```python
a = tensor([[ 0,  1,  2],
            [ 3,  4,  5],
            [ 6,  7,  8],
            [ 9, 10, 11]])
b = tensor([[0, 1, 2],
            [0, 1, 2],
            [0, 1, 2],
            [0, 1, 2]])
a * b
```


å¦‚æœäºŒè€…å½¢çŠ¶ä¸åŒå‘¢? å¯ä»¥éå† row / col è®¡ç®—å¹¶ç»„è£…ç»“æœ
```python
c = torch.zeros(a.shape)
ar, ac = a.shape
for i in range(ar):
    c[i] = a[i] * b
```
ä½†è¿™æ ·å¾ˆæ…¢: Python çš„ loop æ˜¯ python å®ç°çš„, æ•ˆç‡è¿œä½äº C å®ç°çš„ tensor è¿ç®—.
æ‰€ä»¥éœ€è¦ä¸€ä¸ªæ–¹æ³•, æŠŠ b æ‹‰ä¼¸æˆ a ä¸€æ ·çš„å½¢çŠ¶

# broadcast è§„åˆ™
ä¸¤ä¸ªå¤§å° (`len(a.shape)`, æˆ–è€… `t.ndim`) ä¸ç›¸åŒçš„ tensor è¿›è¡Œè®¡ç®—æ—¶, å¯ä»¥æŠŠè¾ƒå°çš„ä¸€æ–¹æ‹‰ä¼¸æˆä¸è¾ƒå¤§çš„ç›¸åŒ
å¯¹äº a, b ä¸¤ ä¸ªtensor, æ‹‰ä¼¸æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¿›è¡Œ:
> 1. ä»æœ€åä¸€ä¸ª dim å¼€å§‹é€ä¸ªæ¯”è¾ƒ
> 2. äºŒè€…çš„ size ç›¸åŒçš„è¯ä¸éœ€è¦æ‹‰ä¼¸, ç»§ç»­æ¯”è¾ƒå‰ä¸€ä¸ª
> 3. a çš„ dim ä¸å­˜åœ¨, æˆ–è€… size = 1, åˆ™ a åœ¨è¿™ä¸ª dim ä¸Šè¿›è¡Œ "å¤åˆ¶"
> 4. â€¦â€¦ ç›´åˆ°æ‰€æœ‰ dim å¤„ç†å®Œ


## ä¸¾å‡ ä¸ªä¾‹å­
A, B, C, D å½¢çŠ¶å¦‚ä¸‹:
A: 5 x 1
B: 1 x 6
C: 6
D: 1
C æ˜¯æœ‰ 6 ä¸ªå…ƒç´ çš„ vector, D æ˜¯ scalar
é€šè¿‡ broadcasting è¿›è¡Œè¿ç®—
```
A      (rank 2 tensor):  5 x 1
B      (rank 2 tensor):  1 x 6
Result (rank 2 tensor):  5 x 6
```
A çš„ç¬¬ä¸€åˆ— `a[:, 0]` åœ¨ x è½´ (dim 0) æ–¹å‘ä¸Šå¤åˆ¶ 6 æ¬¡, A è¡¨ç°ä¸º 5 x 6
B çš„ç¬¬ä¸€è¡Œ `b[0, :]` åœ¨ y è½´æ–¹å‘ä¸Šå¤åˆ¶ 5 æ¬¡

```
B      (rank 2 tensor):  1 x 6
C      (rank 1 tensor):      6
Result (rank 2 tensor):  1 x 6
```
C ä¸ B æœ€åä¸€ä¸ª dim ç›¸åŒ, C è¡¥ä¸Šç¼ºå°‘çš„ dim, è¡¨ç°ä¸º 1 x 6

```
A      (rank 2 tensor):  5 x 1
D      (scalar       ):      1
Result (rank 2 tensor):  5 x 1
```
D çš„å”¯ä¸€ä¸€ä¸ªå…ƒç´ åœ¨æ¯ä¸€ä¸ªä½ç½®ä¸Šå¤åˆ¶, D è¡¨ç°ä¸º 5 x 1

# broadcasting å®ç°
å°†è¾ƒå°çš„ tensor å¤åˆ¶å¤šä»½ä»¥ä¾¿è¾ƒå¤§çš„è¿›è¡ŒåŒ¹é…,  åœ¨å¤„ç†å¾ˆå¤§çš„ tensor è¿ç®—æ—¶ä¼šæ¶ˆè€—å¾ˆå¤šæ—¶é—´å’Œå†…å­˜, broadcasting çš„å®ç°å¾ˆèªæ˜, å¹¶ä¸ä¼šå¤åˆ¶æ•°æ®

`tesnor.expand_as` å°† b æ‹‰ä¼¸åˆ°ä¸ a å¤§å°ç›¸åŒ, å’Œ broadcasting é‡Œä¸€æ ·
```python
b = b.expand_as(a)
b.shape, b

# Output:
(torch.Size([4, 3]),
 tensor([[0, 1, 2],
         [0, 1, 2],
         [0, 1, 2],
         [0, 1, 2]]))
```
ä½†æ˜¯å®é™…ä¸Š b çš„åº•å±‚æ•°æ®æ²¡æœ‰å¤åˆ¶
```python
b.storage()

# Output:
 0
 1
 2
[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 3]
```

ç§˜å¯†å°±åœ¨äºæ§åˆ¶åœ¨å„ä¸ª dim (axis) ä¸Šç§»åŠ¨çš„æ­¥é•¿ (stride)
```python
b.stride(), b.shape

# Output:
((0, 1), torch.Size([4, 3]))
```
æƒ³è±¡æœ‰ä¸€ä¸ª cursor åœ¨ b çš„ row ä¸Šç§»åŠ¨, å½“éœ€è¦ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ª row æ—¶, å› ä¸º tride = 0, cursor ä½ç½®ä¸ä¼šå‘ç”Ÿå˜åŒ–